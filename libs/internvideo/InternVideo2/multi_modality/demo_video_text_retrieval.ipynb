{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/flash_attn/ops/fused_dense.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/flash_attn/ops/fused_dense.py:71: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output, *args):\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/flash_attn/ops/fused_dense.py:252: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/flash_attn/ops/fused_dense.py:349: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output, *args):\n",
      "/code/libs/internvideo/InternVideo2/multi_modality/models/backbones/internvideo2/internvl_clip_vision.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/code/libs/internvideo/InternVideo2/multi_modality/models/backbones/internvideo2/internvideo2.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/code/libs/internvideo/InternVideo2/multi_modality/models/backbones/internvideo2/internvideo2_clip_vision.py:143: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-14 19:40:52,939] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hglee/.conda/envs/iv2/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/hglee/.conda/envs/iv2/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: A person dressed in a blue jacket shovels the snow-covered pavement outside their house. ~ prob: 0.4319\n",
      "text: A playful dog slides down a snowy hill, wagging its tail with delight. ~ prob: 0.3569\n",
      "text: A man in a gray hat and coat walks through the snowy yard, carefully navigating around the trees. ~ prob: 0.0925\n",
      "text: A person in a blue jacket walks their pet on a leash, enjoying a peaceful winter walk among the trees. ~ prob: 0.0788\n",
      "text: A man in a gray coat walks through the snowy landscape, pulling a sleigh loaded with toys. ~ prob: 0.0163\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/code/libs/internvideo/InternVideo2/multi_modality')\n",
    "import cv2\n",
    "\n",
    "from demo_config import (Config,\n",
    "                    eval_dict_leaf)\n",
    "\n",
    "from demo.utils import (retrieve_text,\n",
    "                  _frame_from_video,\n",
    "                  setup_internvideo2)\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture('demo/example1.mp4')\n",
    "frames = [x for x in _frame_from_video(video)]  # 40 x [480, 640, 3]\n",
    "\n",
    "text_candidates = [\"A playful dog and its owner wrestle in the snowy yard, chasing each other with joyous abandon.\",\n",
    "                   \"A man in a gray coat walks through the snowy landscape, pulling a sleigh loaded with toys.\",\n",
    "                   \"A person dressed in a blue jacket shovels the snow-covered pavement outside their house.\",\n",
    "                   \"A pet dog excitedly runs through the snowy yard, chasing a toy thrown by its owner.\",\n",
    "                   \"A person stands on the snowy floor, pushing a sled loaded with blankets, preparing for a fun-filled ride.\",\n",
    "                   \"A man in a gray hat and coat walks through the snowy yard, carefully navigating around the trees.\",\n",
    "                   \"A playful dog slides down a snowy hill, wagging its tail with delight.\",\n",
    "                   \"A person in a blue jacket walks their pet on a leash, enjoying a peaceful winter walk among the trees.\",\n",
    "                   \"A man in a gray sweater plays fetch with his dog in the snowy yard, throwing a toy and watching it run.\",\n",
    "                   \"A person bundled up in a blanket walks through the snowy landscape, enjoying the serene winter scenery.\"]\n",
    "\n",
    "config = Config.from_file('demo/internvideo2_stage2_config.py')\n",
    "config = eval_dict_leaf(config)\n",
    "\n",
    "intern_model, tokenizer = setup_internvideo2(config)\n",
    "\n",
    "texts, probs = retrieve_text(frames, text_candidates, model=intern_model, topk=5, config=config)\n",
    "\n",
    "for t, p in zip(texts, probs):\n",
    "    print(f'text: {t} ~ prob: {p:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 224, 224])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/code/libs/internvideo/InternVideo2/multi_modality')\n",
    "import torch\n",
    "import numpy as np\n",
    "from decord import VideoReader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms._transforms_video import NormalizeVideo, CenterCropVideo\n",
    "from pytorchvideo import transforms as pv_transforms\n",
    "\n",
    "video_transform = transforms.Compose(\n",
    "    [\n",
    "        pv_transforms.ShortSideScale(256),\n",
    "        pv_transforms.Div255(),\n",
    "        CenterCropVideo(224),\n",
    "        NormalizeVideo(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vr = VideoReader('demo/example1.mp4')\n",
    "num_frames = len(vr)\n",
    "frames = torch.from_numpy(vr.get_batch(np.arange(0, num_frames, num_frames // 4)[:4]).asnumpy()).float()\n",
    "frames = video_transform(frames.permute(3, 0, 1, 2))\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/hglee/.conda/envs/iv2/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_feat = intern_model.get_vid_feat(frames.permute(1, 0, 2, 3)[None].cuda())\n",
    "vid_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_feat = intern_model.get_txt_feat(text_candidates)\n",
    "txt_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01341 0.00977 0.26432 0.00598 0.00018 0.06495 0.53769 0.09439 0.00479 0.00451]]\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(suppress=True, precision=5, linewidth=200):\n",
    "    print((100 * vid_feat @ txt_feat.T).softmax(dim=-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: A playful dog slides down a snowy hill, wagging its tail with delight. ~ prob: 0.5377\n",
      "text: A person dressed in a blue jacket shovels the snow-covered pavement outside their house. ~ prob: 0.2643\n",
      "text: A person in a blue jacket walks their pet on a leash, enjoying a peaceful winter walk among the trees. ~ prob: 0.0944\n",
      "text: A man in a gray hat and coat walks through the snowy yard, carefully navigating around the trees. ~ prob: 0.0650\n",
      "text: A playful dog and its owner wrestle in the snowy yard, chasing each other with joyous abandon. ~ prob: 0.0134\n"
     ]
    }
   ],
   "source": [
    "top_probs, top_labels = (100 * vid_feat @ txt_feat.T).softmax(dim=-1).cpu().topk(5, dim=-1)\n",
    "for prob, label in zip(top_probs[0], top_labels[0]):\n",
    "    print(f'text: {text_candidates[label]} ~ prob: {prob:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
