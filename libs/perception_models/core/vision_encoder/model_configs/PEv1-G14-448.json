{
    "embed_dim": 1280,
    "quick_gelu": false,
    "vision_cfg": {
        "image_size": 448,
        "patch_size": 14,
        "layers": 50,
        "width": 1536,
        "output_dim": 1280,        
        "head_width": 96,
        "heads": 16,
        "mlp_ratio": 5.833333334,
        "global_layers": -1,
        "relative_pos_embed_type": "rope_2d",
        "pos_embed_type": "learnable",
        "pool_type": "attn",
        "embed_cls_token": false
    },
    "text_cfg": {
        "context_length": 72,
        "vocab_size": 49408,
        "width": 1280,
        "output_dim": 1280,
        "heads": 20,
        "layers": 24
    }
}

