{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Usage:\n",
    "\n",
    "python3 -m sglang.launch_server --model-path lmms-lab/llava-onevision-qwen2-72b-ov --port=30000 --tp-size=8 --chat-template=chatml-llava\n",
    "\n",
    "python3 http_llava_onevision_test.py\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import requests\n",
    "from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "\n",
    "# pip install httpx==0.23.3\n",
    "# pip install decord\n",
    "# pip install protobuf==3.20.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_video(url, cache_dir):\n",
    "    file_path = os.path.join(cache_dir, \"jobs.mp4\")\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    print(f\"File downloaded and saved to: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def create_openai_client(base_url):\n",
    "    return openai.Client(api_key=\"EMPTY\", base_url=base_url)\n",
    "\n",
    "\n",
    "def image_stream_request_test(client):\n",
    "    print(\"----------------------Image Stream Request Test----------------------\")\n",
    "    stream_request = client.chat.completions.create(\n",
    "        model=\"default\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png\"\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Please describe this image. Please list the benchmarks and the models.\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1024,\n",
    "        stream=True,\n",
    "    )\n",
    "    stream_response = \"\"\n",
    "\n",
    "    for chunk in stream_request:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            stream_response += content\n",
    "            sys.stdout.write(content)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    print('\\n' + \"-\" * 30)\n",
    "\n",
    "\n",
    "def multi_image_stream_request_test(client):\n",
    "    print(\n",
    "        \"----------------------Multi-Images Stream Request Test----------------------\"\n",
    "    )\n",
    "    stream_request = client.chat.completions.create(\n",
    "        model=\"default\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png\"\n",
    "                        },\n",
    "                        \"modalities\": \"multi-images\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://raw.githubusercontent.com/sgl-project/sglang/main/test/lang/example_image.png\"\n",
    "                        },\n",
    "                        \"modalities\": \"multi-images\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"I have shown you two images. Please describe the two images to me.\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1024,\n",
    "        stream=True,\n",
    "    )\n",
    "    stream_response = \"\"\n",
    "\n",
    "    for chunk in stream_request:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            stream_response += content\n",
    "            sys.stdout.write(content)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    print('\\n' + \"-\" * 30)\n",
    "\n",
    "\n",
    "def video_stream_request_test(client, video_path):\n",
    "    print(\"------------------------Video Stream Request Test----------------------\")\n",
    "    messages = prepare_video_messages(video_path)\n",
    "\n",
    "    video_request = client.chat.completions.create(\n",
    "        model=\"default\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "        stream=True,\n",
    "    )\n",
    "    print(\"-\" * 30)\n",
    "    video_response = \"\"\n",
    "\n",
    "    for chunk in video_request:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            video_response += content\n",
    "            sys.stdout.write(content)\n",
    "            sys.stdout.flush()\n",
    "    print('\\n' + \"-\" * 30)\n",
    "\n",
    "\n",
    "def image_speed_test(client):\n",
    "    print(\"----------------------Image Speed Test----------------------\")\n",
    "    start_time = time.time()\n",
    "    request = client.chat.completions.create(\n",
    "        model=\"default\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png\"\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Please describe this image. Please list the benchmarks and the models.\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    response = request.choices[0].message.content\n",
    "    print(response)\n",
    "    print(\"-\" * 30)\n",
    "    print_speed_test_results(request, start_time, end_time)\n",
    "\n",
    "\n",
    "def video_speed_test(client, video_path):\n",
    "    print(\"------------------------Video Speed Test------------------------\")\n",
    "    messages = prepare_video_messages(video_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    video_request = client.chat.completions.create(\n",
    "        model=\"default\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    video_response = video_request.choices[0].message.content\n",
    "    print(video_response)\n",
    "    print(\"-\" * 30)\n",
    "    print_speed_test_results(video_request, start_time, end_time)\n",
    "\n",
    "\n",
    "def prepare_video_messages(video_path):\n",
    "    max_frames_num = 32\n",
    "    vr = VideoReader(video_path, ctx=cpu(0))\n",
    "    total_frame_num = len(vr)\n",
    "    uniform_sampled_frames = np.linspace(\n",
    "        0, total_frame_num - 1, max_frames_num, dtype=int\n",
    "    )\n",
    "    frame_idx = uniform_sampled_frames.tolist()\n",
    "    frames = vr.get_batch(frame_idx).asnumpy()\n",
    "\n",
    "    base64_frames = []\n",
    "    for frame in frames:\n",
    "        pil_img = Image.fromarray(frame)\n",
    "        buff = io.BytesIO()\n",
    "        pil_img.save(buff, format=\"JPEG\")\n",
    "        base64_str = base64.b64encode(buff.getvalue()).decode(\"utf-8\")\n",
    "        base64_frames.append(base64_str)\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": []}]\n",
    "\n",
    "    for base64_frame in base64_frames:\n",
    "        frame_format = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_frame}\"},\n",
    "            \"modalities\": \"video\",\n",
    "        }\n",
    "        messages[0][\"content\"].append(frame_format)\n",
    "\n",
    "    prompt = {\"type\": \"text\", \"text\": \"Please describe the video in detail.\"}\n",
    "    messages[0][\"content\"].append(prompt)\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "def print_speed_test_results(request, start_time, end_time):\n",
    "    total_tokens = request.usage.total_tokens\n",
    "    completion_tokens = request.usage.completion_tokens\n",
    "    prompt_tokens = request.usage.prompt_tokens\n",
    "\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Completion tokens: {completion_tokens}\")\n",
    "    print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "    print(f\"Token per second: {total_tokens / (end_time - start_time)}\")\n",
    "    print(f\"Completion token per second: {completion_tokens / (end_time - start_time)}\")\n",
    "    print(f\"Prompt token per second: {prompt_tokens / (end_time - start_time)}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    url = \"https://raw.githubusercontent.com/EvolvingLMMs-Lab/sglang/dev/onevision_local/assets/jobs.mp4\"\n",
    "    cache_dir = os.path.expanduser(\"/data/gunsbrother/.cache\")\n",
    "    video_path = download_video(url, cache_dir)\n",
    "\n",
    "    client = create_openai_client(\"http://127.0.0.1:30000/v1\")\n",
    "\n",
    "    image_stream_request_test(client)\n",
    "    multi_image_stream_request_test(client)\n",
    "    video_stream_request_test(client, video_path)\n",
    "    image_speed_test(client)\n",
    "    video_speed_test(client, video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to: /data/gunsbrother/.cache/jobs.mp4\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/EvolvingLMMs-Lab/sglang/dev/onevision_local/assets/jobs.mp4\"\n",
    "cache_dir = os.path.expanduser(\"/data/gunsbrother/.cache\")\n",
    "p_video = download_video(url, cache_dir)\n",
    "\n",
    "client_llava = create_openai_client(\"http://163.180.160.54:30012/v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stream_request_test(client_llava)\n",
    "multi_image_stream_request_test(client_llava)\n",
    "video_stream_request_test(client_llava, p_video)\n",
    "image_speed_test(client_llava)\n",
    "video_speed_test(client_llava, p_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_stream_request_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      2\u001b[0m p_anom_video \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/gunsbrother/repos/vlm/datasets/anomaly-detection-dataset/Anomaly-Videos-Part-2/Fighting/Fighting003_x264.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvideo_stream_request_test\u001b[49m(client_llava, \u001b[38;5;28mstr\u001b[39m(p_anom_video))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'video_stream_request_test' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p_anom_video = Path('/data/gunsbrother/repos/vlm/datasets/anomaly-detection-dataset/Anomaly-Videos-Part-2/Fighting/Fighting003_x264.mp4')\n",
    "video_stream_request_test(client_llava, str(p_anom_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segment_idx': 0, 'start_idx': 0, 'end_idx': 59, 'response': 'The video captures a scene at a subway station. The platform is adorned with a vibrant, colorful floor design. A group of people, including a man in a red jacket, are standing near the platform edge. The subway train is not visible in the frame. The atmosphere is calm, and the people appear to be waiting for the train to arrive.'}\n",
      "{'segment_idx': 1, 'start_idx': 60, 'end_idx': 119, 'response': 'The video captures a bustling subway station with a colorful floor, where multiple individuals are seen waiting for the train. The station is well-lit with overhead lights, and there are large maps on the walls providing information about train routes. The people in the video are dressed in various styles of clothing, and some are carrying backpacks. The train tracks are visible on the left side of the frame, and the train itself is not seen in the video.'}\n",
      "{'segment_idx': 2, 'start_idx': 120, 'end_idx': 179, 'response': 'The video captures a static scene at a subway station platform. The platform is adorned with a vibrant, colorful floor design. There are several individuals present, including a person standing near the center of the frame, wearing a backpack and looking at a map or information board. The background features a subway train on the tracks, and the platform is equipped with safety barriers and signs. The lighting is artificial, typical of an underground station, and the overall atmosphere is calm and orderly.'}\n",
      "{'segment_idx': 3, 'start_idx': 180, 'end_idx': 239, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a vibrant, colorful floor design. A person wearing a backpack is standing near a large, rectangular map of the subway system, which is mounted on a metal frame. The map is detailed, showing various lines and stations. In the background, there are other passengers waiting, some standing and others sitting on the platform. The lighting is artificial, typical of an underground station, and the overall atmosphere is calm and orderly.'}\n",
      "{'segment_idx': 4, 'start_idx': 240, 'end_idx': 299, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a vibrant, colorful floor design. There are several people present, including a person wearing a backpack who appears to be looking at a map or information board. The lighting is artificial, typical of an underground station, and the overall atmosphere is calm and orderly.'}\n",
      "{'segment_idx': 5, 'start_idx': 300, 'end_idx': 359, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a vibrant, colorful floor design. There are several people present, including a group of individuals standing near a map display board, possibly discussing or planning their route. The platform has a tiled wall with a pattern, and there are signs and lights above. The train tracks are visible on the left side of the frame, and the train itself is not in view. The atmosphere appears to be calm and routine, typical of a subway station during off-peak hours.'}\n",
      "{'segment_idx': 6, 'start_idx': 360, 'end_idx': 419, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a vibrant, colorful floor design. There are several people present, including a person wearing a gray hoodie and another in a black jacket. The individuals are standing and interacting with each other, with some appearing to be in conversation. The subway train is not visible in the frames provided.'}\n",
      "{'segment_idx': 7, 'start_idx': 420, 'end_idx': 479, 'response': 'The video captures a bustling subway station platform, where multiple individuals are seen walking and standing. The platform is adorned with a vibrant, multicolored floor design, and there is a large map of the subway system prominently displayed. The lighting is artificial, typical of underground stations, and the atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 8, 'start_idx': 480, 'end_idx': 539, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and interacting with each other. The station has a tiled wall with a map, and the lighting is artificial. The atmosphere is busy, with individuals in various attire, including a person in a white hoodie and another in a dark jacket.'}\n",
      "{'segment_idx': 9, 'start_idx': 540, 'end_idx': 599, 'response': 'The video captures a bustling subway station with a colorful floor, where multiple individuals are seen walking, standing, and interacting. The station has a tiled floor with a vibrant pattern, and there are signs and maps on the walls. People are dressed in various styles of clothing, and some are carrying bags or backpacks. The lighting is artificial, typical of underground stations, and the overall atmosphere is busy and dynamic.'}\n",
      "{'segment_idx': 10, 'start_idx': 600, 'end_idx': 659, 'response': 'The video captures a scene in a subway station where several individuals are present. The station has a colorful floor with a pattern of various colors, and there are posters on the walls. The people in the video are engaged in various activities, such as walking, standing, and interacting with each other. The lighting in the station is artificial, and the overall atmosphere appears to be that of a typical day in a busy urban subway station.'}\n",
      "{'segment_idx': 11, 'start_idx': 660, 'end_idx': 719, 'response': 'The video captures a bustling subway station with a colorful floor, where multiple individuals are seen walking and standing. The station has a tiled floor with a vibrant pattern, and there are informational signs and a map visible. People are dressed in various styles of clothing, and some are carrying backpacks. The lighting is artificial, typical of underground stations, and the overall atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 12, 'start_idx': 720, 'end_idx': 779, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking in various directions, some standing near the platform, while others are in motion. The station is well-lit with overhead lights, and there are signs and maps on the walls providing information. The atmosphere is busy, with individuals engaged in their own activities.'}\n",
      "{'segment_idx': 13, 'start_idx': 780, 'end_idx': 839, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking and standing, with some carrying backpacks. The station has a tiled wall with a map of the subway lines. The lighting is artificial, and the atmosphere is typical of a busy transit hub.'}\n",
      "{'segment_idx': 14, 'start_idx': 840, 'end_idx': 899, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a colorful, patterned floor, and there are several individuals present. Some are standing, while others are walking. The background features a subway train on the tracks and a map of the subway system on a wall. The lighting is artificial, typical of an underground station, and the overall atmosphere is that of a busy transit hub.'}\n",
      "{'segment_idx': 15, 'start_idx': 900, 'end_idx': 959, 'response': 'The video captures a bustling subway station with multiple individuals standing and moving around. The station has a colorful floor pattern, and there are signs and maps visible. The people are dressed in various styles of clothing, with some wearing jackets and others in lighter attire. The lighting is artificial, typical of underground stations, and the overall atmosphere is busy and dynamic.'}\n",
      "{'segment_idx': 16, 'start_idx': 960, 'end_idx': 1019, 'response': 'The video captures a bustling subway station with numerous individuals standing and moving around. The station has a colorful floor pattern, and there is a large map on the wall. People are dressed in various styles of clothing, and some are carrying backpacks. The atmosphere is busy, with people either waiting for the train or walking through the station.'}\n",
      "{'segment_idx': 17, 'start_idx': 1020, 'end_idx': 1079, 'response': 'The video captures a scene at a subway station where several individuals are standing on the platform. The platform is adorned with a colorful patterned floor, and there is a map of the subway system visible in the background. The individuals are dressed in various styles of clothing, with some wearing jackets and others in lighter attire. The lighting in the station is artificial, and the overall atmosphere suggests a typical day with passengers waiting for their train.'}\n",
      "{'segment_idx': 18, 'start_idx': 1080, 'end_idx': 1139, 'response': 'The video captures a scene at a subway station where several individuals are waiting on the platform. The platform is adorned with a colorful patterned floor, and there is a large map of the subway system prominently displayed. The individuals are dressed in various styles of clothing, with some wearing jackets and others in lighter attire. The lighting in the station is artificial, and the overall atmosphere is calm and orderly.'}\n",
      "{'segment_idx': 19, 'start_idx': 1140, 'end_idx': 1199, 'response': 'The video captures a scene at a subway station where several individuals are waiting for a train. The platform is adorned with a colorful, patterned floor, and there is a large map of the subway system prominently displayed. The people are standing in various positions, some closer to the edge of the platform, while others are slightly further back. The lighting is artificial, typical of underground stations, and the overall atmosphere is calm and orderly.'}\n",
      "{'segment_idx': 20, 'start_idx': 1200, 'end_idx': 1259, 'response': 'The video captures a bustling subway station with a colorful tiled floor. People are seen standing and walking around, some carrying bags and backpacks. The station has a map of the subway lines on a large sign, and the lighting is artificial, typical of underground stations. The atmosphere is busy, with individuals engaged in various activities such as waiting, talking, and moving through the station.'}\n",
      "{'segment_idx': 21, 'start_idx': 1260, 'end_idx': 1319, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a colorful floor design and has a map of the subway lines on the wall. There are several people present, including two individuals who appear to be engaged in a conversation. The platform is well-lit, and the subway train is visible in the background. The video provides a detailed view of the subway station, showcasing the daily commute of people and the vibrant atmosphere of the station.'}\n",
      "{'segment_idx': 22, 'start_idx': 1320, 'end_idx': 1379, 'response': 'The video captures a bustling subway station with a vibrant, colorful floor design. People are seen walking, standing, and waiting, with some carrying backpacks and handbags. The station has a tiled floor with a mix of pink, blue, yellow, and green patterns, and there are signs and a map on the right side of the frame. The ceiling has fluorescent lights, and the walls are painted in a neutral color.'}\n",
      "{'segment_idx': 23, 'start_idx': 1380, 'end_idx': 1439, 'response': 'The video captures a bustling subway station platform, where multiple individuals are seen walking, standing, and interacting. The platform is adorned with a vibrant, colorful patterned floor, and there is a large map of the subway system prominently displayed. The lighting is artificial, typical of underground stations, and the atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 24, 'start_idx': 1440, 'end_idx': 1499, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and interacting in the station. The station has a tiled floor with a vibrant design, and there are signs and maps visible. The lighting is artificial, typical of underground stations, and the overall atmosphere is busy and dynamic.'}\n",
      "{'segment_idx': 25, 'start_idx': 1500, 'end_idx': 1559, 'response': 'The video captures a bustling subway station platform, where numerous individuals are seen walking, standing, and interacting. The platform is adorned with a vibrant, colorful floor design, and there is a prominent map of the subway system displayed on a large sign. The atmosphere is busy, with people in various states of motion, some in groups and others alone. The lighting is artificial, typical of underground stations, and the overall scene conveys a sense of daily urban commuting.'}\n",
      "{'segment_idx': 26, 'start_idx': 1560, 'end_idx': 1619, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and waiting for the train. The station is well-lit with overhead lights, and there are signs and maps on the walls. The train arrives and departs, and passengers board and exit the train. The atmosphere is busy and typical of a public transportation hub.'}\n",
      "{'segment_idx': 27, 'start_idx': 1620, 'end_idx': 1679, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and interacting with each other. The station has a tiled floor with a vibrant design, and there are signs and maps on the walls. The lighting is artificial, typical of underground stations, and the overall atmosphere is busy and dynamic.'}\n",
      "{'segment_idx': 28, 'start_idx': 1680, 'end_idx': 1739, 'response': 'The video captures a bustling subway station with numerous people moving about. The platform is adorned with a vibrant, colorful floor design, and there are various signs and maps visible. The lighting is artificial, typical of underground stations, and the atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 29, 'start_idx': 1740, 'end_idx': 1799, 'response': 'The video captures a bustling subway station with a colorful floor design. People are seen walking, standing, and waiting, with some carrying bags and backpacks. The station has a tiled wall with a map, and the lighting is artificial, typical of underground transit systems.'}\n",
      "{'segment_idx': 30, 'start_idx': 1800, 'end_idx': 1859, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and interacting with each other. The station is well-lit with artificial lighting, and there are signs and maps visible on the walls. The atmosphere is busy, with individuals in various states of motion, some in groups and others alone.'}\n",
      "{'segment_idx': 31, 'start_idx': 1860, 'end_idx': 1919, 'response': 'The video depicts a crowded subway station with a colorful floor design. People are seen moving in and out of the frame, some walking briskly, while others appear to be standing or waiting. The station has a tiled floor with a vibrant pattern, and there are signs and maps on the walls. The lighting is artificial, typical of underground stations, and the overall atmosphere suggests a busy time of day.'}\n",
      "{'segment_idx': 32, 'start_idx': 1920, 'end_idx': 1979, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and waiting, with some looking at a map or information board. The station has a tiled floor, walls with advertisements, and a ceiling with fluorescent lights. The atmosphere is busy, with individuals in various attire, including jackets, hats, and backpacks.'}\n",
      "{'segment_idx': 33, 'start_idx': 1980, 'end_idx': 2039, 'response': 'The video captures a bustling subway station with numerous people waiting for the train. The platform is adorned with a colorful patterned floor, and there are various signs and maps visible. The crowd consists of individuals of different ages and attire, some carrying backpacks and handbags. The train tracks are visible on the left side of the frame, and the train itself is not seen in the video. The atmosphere is busy, with people standing and moving around, indicating a typical day at a subway station.'}\n",
      "{'segment_idx': 34, 'start_idx': 2040, 'end_idx': 2099, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and interacting with each other. Some individuals are carrying backpacks, and there is a prominent map on a stand. The station is well-lit with overhead lights, and the atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 35, 'start_idx': 2100, 'end_idx': 2159, 'response': 'The video depicts a busy subway station with a colorful floor. People are seen walking, standing, and interacting with each other. Some individuals are carrying bags, and there is a map on a stand in the background. The scene is dynamic, with people moving in and out of the frame.'}\n",
      "{'segment_idx': 36, 'start_idx': 2160, 'end_idx': 2219, 'response': 'The video captures a scene in a subway station. The floor is adorned with a vibrant, colorful pattern. People are seen walking and standing around, some carrying backpacks. The station has a tiled wall with a sign that reads \"出口\" (Exit). The atmosphere is busy, with individuals moving in different directions.'}\n",
      "{'segment_idx': 37, 'start_idx': 2220, 'end_idx': 2279, 'response': 'The video captures a sequence of events in a subway station. It begins with a person in a white shirt and dark pants running towards the camera. As the video progresses, the person continues to run, maintaining a consistent pace and direction. The subway station has a colorful floor with a pattern of various colors, including pink, blue, green, and yellow. There are also signs and a map visible in the background. The person runs past the camera and eventually exits the frame. The video concludes with the person no longer visible, and the camera focuses on the empty subway station.'}\n",
      "{'segment_idx': 38, 'start_idx': 2280, 'end_idx': 2339, 'response': 'The video captures a bustling subway station with a vibrant, colorful floor. People are seen walking, standing, and waiting, with some carrying backpacks and handbags. The station has a tiled wall with a pattern, and there are signs and maps on the walls. The lighting is artificial, and the atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 39, 'start_idx': 2340, 'end_idx': 2399, 'response': 'The video captures a scene at a subway station. It shows a group of people waiting on the platform, with a colorful tiled floor and a map of the subway lines visible. The individuals are dressed in various styles of clothing, including a person wearing a pink headscarf and a person in a white shirt with a backpack. The platform is well-lit, and the subway train is not visible in the frames provided.'}\n",
      "{'segment_idx': 40, 'start_idx': 2400, 'end_idx': 2459, 'response': 'The video captures a scene at a subway station where several individuals are waiting for the train. The platform is adorned with a colorful patterned floor, and there are various signs and maps visible. The people are dressed in casual attire, with some wearing backpacks. The train arrives, and passengers board it, while others continue to wait. The atmosphere is typical of a busy subway station, with people coming and going.'}\n",
      "{'segment_idx': 41, 'start_idx': 2460, 'end_idx': 2519, 'response': 'The video captures a bustling subway station with a colorful floor pattern. People are seen walking, standing, and interacting with each other. The station has a tiled wall with a map of the subway lines, and there are signs and advertisements on the walls. The lighting is artificial, typical of underground stations, and the atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 42, 'start_idx': 2520, 'end_idx': 2579, 'response': 'The video captures a bustling subway station with a colorful floor, where multiple individuals are seen walking, standing, and interacting. The station has a tiled floor with a vibrant pattern, and there are signs and maps on the walls. People are dressed in various styles of clothing, and some are carrying bags or backpacks. The atmosphere is busy, with people moving in different directions, some looking at the maps, and others engaged in conversations or looking around.'}\n",
      "{'segment_idx': 43, 'start_idx': 2580, 'end_idx': 2639, 'response': 'The video captures a scene at a subway station platform. It shows a group of people standing and waiting for the train. The platform has a colorful patterned floor, and there are signs and maps visible. The train arrives, and the people start to board. The video focuses on the movement and interaction of the people as they get on the train.'}\n",
      "{'segment_idx': 44, 'start_idx': 2640, 'end_idx': 2699, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a vibrant, colorful mural on the ground. There are several people present, including a person wearing a pink headscarf and a long black coat, another person in a green jacket and jeans, and a third person in a white shirt and blue jeans. The individuals are engaged in various activities, such as walking, standing, and interacting with each other. The subway train is not visible in the video.'}\n",
      "{'segment_idx': 45, 'start_idx': 2700, 'end_idx': 2759, 'response': 'The video captures a scene at a subway station platform. The platform is adorned with a vibrant, colorful pattern on the floor. There are several people present, including a woman in a black dress, a man in a blue shirt, and another woman in a green jacket. The woman in the black dress is walking towards the camera, while the man in the blue shirt is standing near a map of the subway system. The woman in the green jacket is walking away from the camera. The video shows the people moving around the platform, with the woman in the black dress and the man in the blue shirt being the most prominent figures.'}\n",
      "{'segment_idx': 46, 'start_idx': 2760, 'end_idx': 2819, 'response': 'The video captures a bustling subway station with a colorful floor, where passengers are seen walking, standing, and interacting. The station is well-lit with overhead lights, and there are signs and maps on the walls. The camera angle is from a low perspective, possibly from a seated position.'}\n",
      "{'segment_idx': 47, 'start_idx': 2820, 'end_idx': 2879, 'response': 'The video captures a bustling subway station with a colorful tiled floor. People are seen walking, standing, and interacting with each other. Some individuals are carrying bags, and one person is seen holding a map. The station has a tiled wall with a map and a bench. The lighting is artificial, and the overall atmosphere is busy and typical of a subway station.'}\n",
      "{'segment_idx': 48, 'start_idx': 2880, 'end_idx': 2939, 'response': 'The video captures a bustling subway station with multiple individuals moving about. The platform is adorned with colorful tiles, and there are various signs and maps visible. People are seen walking, standing, and interacting with each other. The subway train is visible in the background, and the atmosphere is busy with commuters.'}\n",
      "{'segment_idx': 49, 'start_idx': 2940, 'end_idx': 2999, 'response': 'The video captures a bustling subway station with a colorful tiled floor. People are seen walking, standing, and interacting with each other. A train arrives and departs, and individuals are seen boarding and alighting. The station is well-lit with overhead lights, and there are maps and signs visible. The atmosphere is busy, with people in various states of motion.'}\n",
      "{'segment_idx': 50, 'start_idx': 3000, 'end_idx': 3059, 'response': 'The video captures a bustling subway station platform with a colorful floor design. People are seen walking, standing, and interacting with each other. A train arrives and departs, and the platform remains busy with passengers.'}\n"
     ]
    }
   ],
   "source": [
    "from diffusers.utils import make_image_grid, export_to_gif\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "\n",
    "def get_frames(p_video, max_frames_num=32):\n",
    "    duration_sec = 2\n",
    "    FPS = 30\n",
    "    max_frames_num = 32\n",
    "    num_frames_segment = int(duration_sec * FPS)\n",
    "\n",
    "    vr = VideoReader(str(p_video), ctx=cpu(0))\n",
    "    total_frame_num = len(vr)\n",
    "    num_segments = total_frame_num // num_frames_segment\n",
    "    for segment_idx in range(num_segments):\n",
    "        segment_start_idx = segment_idx * num_frames_segment\n",
    "        segment_end_idx = segment_start_idx + num_frames_segment - 1\n",
    "        uniform_sampled_frames = np.linspace(segment_start_idx, segment_end_idx, max_frames_num, dtype=int)\n",
    "        frame_idx = uniform_sampled_frames.tolist()\n",
    "        frames = vr.get_batch(frame_idx).asnumpy()\n",
    "        yield {\n",
    "            'frames': frames,\n",
    "            'segment_idx': segment_idx,\n",
    "            'total_segments': num_segments,\n",
    "            'segment_start_idx': segment_start_idx,\n",
    "            'segment_end_idx': segment_end_idx,\n",
    "        }\n",
    "\n",
    "def generate_video_caption(client, frames, prompt: str = \"Please describe the video in detail.\"):\n",
    "    # duration_sec = 1\n",
    "    # FPS = 30\n",
    "    # max_frames_num = 32\n",
    "    # num_frames_segment = int(duration_sec * FPS)\n",
    "    # print(f\"num_frames_segment: {num_frames_segment}\")\n",
    "\n",
    "    # vr = VideoReader(video_path, ctx=cpu(0))\n",
    "    # total_frame_num = len(vr)\n",
    "    # num_segments = total_frame_num // num_frames_segment\n",
    "    # print(f\"num_segments: {num_segments}\")\n",
    "    # segment_idx = 75\n",
    "    # segment_start_idx = segment_idx * num_frames_segment\n",
    "    # uniform_sampled_frames = np.linspace(segment_start_idx, segment_start_idx + num_frames_segment - 1, max_frames_num, dtype=int)\n",
    "    # frame_idx = uniform_sampled_frames.tolist()\n",
    "    # frames = vr.get_batch(frame_idx).asnumpy()\n",
    "\n",
    "    base64_frames = []\n",
    "    # imgs = []\n",
    "    for frame in frames:\n",
    "        pil_img = Image.fromarray(frame)\n",
    "        # imgs.append(pil_img)\n",
    "        buff = io.BytesIO()\n",
    "        pil_img.save(buff, format=\"JPEG\")\n",
    "        base64_str = base64.b64encode(buff.getvalue()).decode(\"utf-8\")\n",
    "        base64_frames.append(base64_str)\n",
    "    # export_to_gif(imgs, '/tmp/tmp.gif', fps=30)\n",
    "    # display(IPImage(open('/tmp/tmp.gif', 'rb').read()))\n",
    "    # print()\n",
    "\n",
    "    content = []\n",
    "    for base64_frame in base64_frames:\n",
    "        frame_format = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_frame}\"},\n",
    "            \"modalities\": \"video\",\n",
    "        }\n",
    "        content.append(frame_format)\n",
    "    content.append({\n",
    "        'type': 'text',\n",
    "        'text': prompt,\n",
    "    })\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "    video_request = client.chat.completions.create(\n",
    "        model=\"default\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    video_response = video_request.choices[0].message.content\n",
    "    return video_response\n",
    "\n",
    "responses = []\n",
    "for frame_dict in get_frames(p_anom_video):\n",
    "    video_response: str = generate_video_caption(client_llava, frame_dict['frames'], prompt='Describe the video in a few sentences.')\n",
    "    response = {\n",
    "        'segment_idx': frame_dict['segment_idx'],\n",
    "        'start_idx': frame_dict['segment_start_idx'],\n",
    "        'end_idx': frame_dict['segment_end_idx'],\n",
    "        'response': video_response,\n",
    "    }\n",
    "    responses.append(response)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0.2][0.2][0.1][0.1][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.1][0.1][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.1][0.1][0.2][0.1][0.1][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2][0.2]\n"
     ]
    }
   ],
   "source": [
    "context_prompt = \"If you were a law enforcement agency, how would you rate this scene on a scale from 0 to 1, with 0 representing a standard scene and 1 denoting a scene with suspicious activities?\"\n",
    "# context_prompt = \"If you were a law enforcement agency, how would you rate this scene on a scale from 0 to 1, with 0 representing a standard scene and 1 denoting a scene with unusual activities?\"\n",
    "format_prompt = \"Please provide the response in the form of a Python list and respond with only one number in the provided list below [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] without any textual explanation. It should begin with '[' and end with  ']'.\"\n",
    "prompt = f\"{context_prompt} {format_prompt}\\n\\nScene description: {video_response.replace('\\n\\n', ' ').replace('\\n', ' ')}\"\n",
    "\n",
    "# print(prompt)\n",
    "# print(flush=True)\n",
    "\n",
    "\n",
    "def chat(client, prompt: str):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': f'The following is a scene description. {context_prompt} {format_prompt}',\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ]\n",
    "    request = client.chat.completions.create(\n",
    "        model=\"default\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in request:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            response += content\n",
    "            sys.stdout.write(content)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    return response\n",
    "\n",
    "client_llama = create_openai_client(\"http://163.180.160.54:30000/v1\")\n",
    "for response_dict in responses:\n",
    "    response = chat(client_llama, response_dict['response'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# 작은 라바\n",
    "python3 -m sglang.launch_server --model-path lmms-lab/llava-onevision-qwen2-7b-ov --port=30000 --tp-size=1 --chat-template=chatml-llava --host=$(hostname -i)\n",
    "\n",
    "# 큰 라바\n",
    "NCCL_SOCKET_IFNAME=enp28s0 python3 -m sglang.launch_server --model-path lmms-lab/llava-onevision-qwen2-72b-ov --tp-size=16 --nnodes=2 --node-rank=0 --chat-template=chatml-llava --nccl-init-addr $(hostname -i):23307 --host=$(hostname -i) --port=30000\n",
    "NCCL_SOCKET_IFNAME=enp28s0 python3 -m sglang.launch_server --model-path lmms-lab/llava-onevision-qwen2-72b-ov --tp-size=16 --nnodes=2 --node-rank=1 --chat-template=chatml-llava --nccl-init-addr 163.180.160.50:23307 --host=163.180.160.50\n",
    "\n",
    "# 라마\n",
    "python3 -m sglang.launch_server --model-path meta-llama/Llama-3.2-3B-Instruct --port=30000 --tp-size=1 --host=$(hostname -i)\n",
    "# 딥식\n",
    "python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-R1-Distill-Llama-8B --port=30000 --tp-size=1 --host=$(hostname -i)\n",
    "python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-R1-Distill-Llama-70B --port=30000 --tp-size=1 --host=$(hostname -i)\n",
    "```\n",
    "\n",
    "# salloc 할당\n",
    "```bash\n",
    "salloc -N 2 --gres=gpu:8 --ntasks-per-node=8 --cpus-per-task=8 --mem-per-gpu=43G -p debug_grad -x 'ariel-m1,ariel-k[1,2]' -t 4:00:00 --job-name not-interactive\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>label</th>\n",
       "      <th>s1</th>\n",
       "      <th>e1</th>\n",
       "      <th>s2</th>\n",
       "      <th>e2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse028_x264.mp4</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>165</td>\n",
       "      <td>240</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse030_x264.mp4</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>1275</td>\n",
       "      <td>1360</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrest001_x264.mp4</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>1185</td>\n",
       "      <td>1485</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arrest007_x264.mp4</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>1530</td>\n",
       "      <td>2160</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrest024_x264.mp4</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>1005</td>\n",
       "      <td>3105</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Vandalism007_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>240</td>\n",
       "      <td>750</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Vandalism015_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>2010</td>\n",
       "      <td>2700</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Vandalism017_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>270</td>\n",
       "      <td>330</td>\n",
       "      <td>780</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Vandalism028_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>1830</td>\n",
       "      <td>1980</td>\n",
       "      <td>2400</td>\n",
       "      <td>2670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Vandalism036_x264.mp4</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>540</td>\n",
       "      <td>780</td>\n",
       "      <td>990</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     video      label    s1    e1    s2    e2\n",
       "0        Abuse028_x264.mp4      Abuse   165   240    -1    -1\n",
       "1        Abuse030_x264.mp4      Abuse  1275  1360    -1    -1\n",
       "2       Arrest001_x264.mp4     Arrest  1185  1485    -1    -1\n",
       "3       Arrest007_x264.mp4     Arrest  1530  2160    -1    -1\n",
       "4       Arrest024_x264.mp4     Arrest  1005  3105    -1    -1\n",
       "..                     ...        ...   ...   ...   ...   ...\n",
       "285  Vandalism007_x264.mp4  Vandalism   240   750    -1    -1\n",
       "286  Vandalism015_x264.mp4  Vandalism  2010  2700    -1    -1\n",
       "287  Vandalism017_x264.mp4  Vandalism   270   330   780   840\n",
       "288  Vandalism028_x264.mp4  Vandalism  1830  1980  2400  2670\n",
       "289  Vandalism036_x264.mp4  Vandalism   540   780   990  1080\n",
       "\n",
       "[290 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "video\n",
       "Abuse/Abuse001_x264.mp4             2729\n",
       "Abuse/Abuse002_x264.mp4              865\n",
       "Abuse/Abuse003_x264.mp4             3699\n",
       "Abuse/Abuse004_x264.mp4            16794\n",
       "Abuse/Abuse005_x264.mp4              949\n",
       "                                   ...  \n",
       "Vandalism/Vandalism046_x264.mp4     2099\n",
       "Vandalism/Vandalism047_x264.mp4     2483\n",
       "Vandalism/Vandalism048_x264.mp4     7183\n",
       "Vandalism/Vandalism049_x264.mp4     7999\n",
       "Vandalism/Vandalism050_x264.mp4      899\n",
       "Name: num_frames, Length: 1900, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "p_ann_test = Path('/data/gunsbrother/repos/vlm/datasets/anomaly-detection-dataset/Temporal_Anomaly_Annotation_for_Testing_Videos.txt')\n",
    "p_num_frames = Path('/data/gunsbrother/repos/vlm/datasets/anomaly-detection-dataset/num_frames_per_video.txt')\n",
    "df_ann_test = pd.read_csv(p_ann_test, sep=r'\\s+', header=None, names=['video', 'label', 's1', 'e1', 's2', 'e2'])\n",
    "df_num_frames = pd.read_csv(p_num_frames, sep=r'\\s+', header=None, names=['video', 'num_frames'])\n",
    "sr_num_frames = df_num_frames.set_index('video')['num_frames']\n",
    "\n",
    "display(df_ann_test)\n",
    "display(sr_num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49952901697214774\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ann_vad = {}\n",
    "for idx, row in df_ann_test.iterrows():\n",
    "    key = f\"{row['label']}/{row['video']}\"\n",
    "    key = key.replace('Normal/', 'Testing_Normal_Videos_Anomaly/')\n",
    "    num_frames = sr_num_frames[key]\n",
    "    bin_label = np.zeros(num_frames, dtype=np.int32)\n",
    "    bin_label[row['s1']:row['e1']] = 1\n",
    "    if row['s2'] != -1:\n",
    "        bin_label[row['s2']:row['e2']] = 1\n",
    "    ann_vad[key] = bin_label\n",
    "\n",
    "fake_preds = {}\n",
    "for key, bin_label in ann_vad.items():\n",
    "    fake_preds[key] = np.random.rand(len(bin_label))\n",
    "\n",
    "# compute AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "all_preds, all_labels = np.array([]), np.array([])\n",
    "for key, bin_label in ann_vad.items():\n",
    "    all_preds = np.concatenate([all_preds, fake_preds[key]])\n",
    "    all_labels = np.concatenate([all_labels, bin_label])\n",
    "auc = roc_auc_score(all_labels, all_preds)\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
