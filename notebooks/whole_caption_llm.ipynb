{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code\n"
     ]
    }
   ],
   "source": [
    "%cd /code/\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing import Literal\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import openai\n",
    "from sglang.utils import (\n",
    "    execute_shell_command,\n",
    "    wait_for_server,\n",
    "    terminate_process,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(\n",
    "    client: openai.Client,\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    model: str = \"default\",\n",
    "):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    while True:\n",
    "        try:\n",
    "            request = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "                # max_tokens=1024,\n",
    "            )\n",
    "        except openai.OpenAIError as e:\n",
    "            print(e)\n",
    "            print('Retrying in 5 seconds...')\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    if request.choices[0].message.content:\n",
    "        response = request.choices[0].message.content\n",
    "    elif request.choices[0].message.refusal:\n",
    "        response = request.choices[0].message.refusal\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODELS = [\n",
    "    'gpt-4o', 'chatgpt-4o-latest',\n",
    "    'gpt-4o-mini',\n",
    "    'o1',\n",
    "    'o1-mini',\n",
    "    'o3-mini',\n",
    "    'gpt-4-turbo',\n",
    "]\n",
    "\n",
    "\n",
    "p_annroot = Path('./data/annotations')\n",
    "p_ann_test = p_annroot / 'Temporal_Anomaly_Annotation_for_Testing_Videos.txt'\n",
    "\n",
    "\n",
    "def generate_llm(\n",
    "    host: str = 'localhost', port: int = 30002,\n",
    "    rank: int = 0, world_size: int = 1,\n",
    "    vlm_model: str = 'lmms-lab/llava-onevision-qwen2-7b-ov',\n",
    "    llm_model: str = 'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    prompt_vlm: str = \"Describe the video in a few sentences.\",\n",
    "    prompt_llm_system_language: Literal['en', 'ko'] = \"en\",\n",
    "    duration_sec = 1,\n",
    "    process_each_segment: bool = True,\n",
    "    debug: bool = False,\n",
    "):\n",
    "    p_vlm_outdir = Path('output/ucf-crime-captions') / f\"prompt={prompt_vlm.replace(' ', '_')}_duration_{duration_sec}s/raw\"\n",
    "    df_ann_test = pd.read_csv(\n",
    "        p_ann_test, sep=r'\\s+', header=None, names=['video', 'label', 's1', 'e1', 's2', 'e2'])\n",
    "    if process_each_segment:\n",
    "        p_llm_outdir = p_vlm_outdir.parent / llm_model.replace('/', '-') / prompt_llm_system_language\n",
    "    else:\n",
    "        assert prompt_llm_system_language == 'en'\n",
    "        p_llm_outdir = p_vlm_outdir.parent / llm_model.replace('/', '-') / 'whole'\n",
    "    p_llm_outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    df_ann_test = df_ann_test.iloc[rank::world_size]\n",
    "\n",
    "    if llm_model not in OPENAI_MODELS:\n",
    "        server_address = f\"http://{host}:{port}\"\n",
    "        print(f'Waiting for LLM server at {server_address}...', flush=True)\n",
    "        wait_for_server(server_address, timeout=600)\n",
    "        client = openai.Client(api_key=\"EMPTY\", base_url=f\"{server_address}/v1\")\n",
    "    else:\n",
    "        print('Using OpenAI API', flush=True)\n",
    "        client = openai.Client(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "    if prompt_llm_system_language == 'en':\n",
    "        context_prompt = \"The following is a scene description. If you were a law enforcement agency, how would you rate this scene on a scale from 0 to 1, with 0 representing a standard scene and 1 denoting a scene with suspicious activities?\"\n",
    "        if process_each_segment:\n",
    "            format_prompt = \"Please provide the response in the form of a Python list and respond with only one number in the provided list below [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] without any textual explanation. It should begin with '[' and end with  ']'.\"\n",
    "        else:\n",
    "            format_prompt = \"Please fill the 'rate' values which are provided as `None` in the description. Rate should respond with only one number in the provided list below [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]. The response should be a Python list of dictionaries with 'segment_idx', 'description', 'reason', and 'rate' keys. Don't write a code nor textual explanation. Just fill the 'rate' values. The response should begin with '[' and end with ']'.\"\n",
    "    elif prompt_llm_system_language == 'ko':\n",
    "        context_prompt = \"다음은 비디오에 대한 설명이야. 만약 너가 경찰이라면 이 장면의 이상한 정도를 0부터 1까지의 점수 중에 어떻게 평가할 거야? 0은 일상적인 장면이고 1은 의심스러운 활동이 있는 장면이야.\"\n",
    "        format_prompt = \"아래에 제공된 목록에서 하나의 숫자로만 응답해줘. [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] 이 숫자는 어떤 설명도 없이 제공되어야 해. '['로 시작해서 ']'로 끝나야 해.\"\n",
    "\n",
    "    system_prompt = f'{context_prompt} {format_prompt}'\n",
    "\n",
    "    for idx, row in tqdm(\n",
    "        df_ann_test.iterrows(), total=len(df_ann_test), mininterval=1, position=0, file=sys.stdout\n",
    "    ):\n",
    "        p_json = (p_vlm_outdir / row['label'] / row['video']).with_suffix('.json')\n",
    "        if not p_json.exists():\n",
    "            print(f\"Skipping generating llm captions of {p_json} as it does not exist\", flush=True)\n",
    "            continue\n",
    "        video_record = json.load(p_json.open())\n",
    "        p_json_new = (p_llm_outdir / video_record['label'] / video_record['video']).with_suffix('.json')\n",
    "        if p_json_new.exists():\n",
    "            print(f\"Skipping {p_json_new}\", flush=True)\n",
    "            continue\n",
    "        print(f'\\nProcessing {p_json}\\n\\t-> {p_json_new}', flush=True)\n",
    "        p_json_new.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        if process_each_segment:\n",
    "            for response_record in video_record['response_records']:\n",
    "                user_prompt = f\"Scene Description: {response_record['response']}\"\n",
    "                llm_response: str = chat(\n",
    "                    client,\n",
    "                    system_prompt=system_prompt,\n",
    "                    user_prompt=user_prompt,\n",
    "                    model=llm_model,\n",
    "                )\n",
    "                response_record['score_raw'] = llm_response\n",
    "                if 'DeepSeek-R1' in llm_model:\n",
    "                    llm_response = re.sub(r'^(?s:.)*</think>', '', llm_response).strip()\n",
    "                try:\n",
    "                    score = eval(llm_response)[0]\n",
    "                except Exception as e:\n",
    "                    print(e, file=sys.stderr)\n",
    "                    print(response_record, llm_response, file=sys.stderr)\n",
    "                    score = None\n",
    "                finally:\n",
    "                    response_record['score'] = score\n",
    "                if debug:\n",
    "                    # print(response_record, flush=True, end='\\n\\n')\n",
    "                    tqdm.write(json.dumps(response_record, indent=2))\n",
    "        else:  # process the whole segments at once\n",
    "            descriptions = []\n",
    "            for response_record in video_record['response_records']:\n",
    "                descriptions.append({\n",
    "                    'segment_idx': response_record['segment_idx'],\n",
    "                    'description': response_record['response'],\n",
    "                    'rate': None,\n",
    "                })\n",
    "            user_prompt = f\"Scene Descriptions: {descriptions}\"\n",
    "            llm_response: str = chat(\n",
    "                client,\n",
    "                system_prompt=system_prompt,\n",
    "                user_prompt=user_prompt,\n",
    "                model=llm_model,\n",
    "            )\n",
    "            if debug:\n",
    "                tqdm.write(json.dumps(llm_response, indent=2))\n",
    "            try:\n",
    "                llm_response = eval(llm_response)\n",
    "            except Exception as e:\n",
    "                print(e, file=sys.stderr)\n",
    "                print(llm_response, file=sys.stderr)\n",
    "                llm_response = []\n",
    "            if len(llm_response) != len(video_record['response_records']):\n",
    "                llm_response = []\n",
    "            if llm_response:\n",
    "                for seg_idx in range(len(video_record['response_records'])):\n",
    "                    video_record['response_records'][seg_idx]['score_raw'] = llm_response[seg_idx].get('rate')\n",
    "                    if isinstance(llm_response[seg_idx].get('rate'), (int, float)):\n",
    "                        video_record['response_records'][seg_idx]['score'] = llm_response[seg_idx].get('rate')\n",
    "                    video_record['response_records'][seg_idx]['reason'] = llm_response[seg_idx].get('reason')\n",
    "        json.dump(video_record, p_json_new.open('w'), indent=2)\n",
    "\n",
    "generate_llm(host='llm_server', llm_model='meta-llama/Llama-3.1-8B-Instruct', debug=False, process_each_segment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
